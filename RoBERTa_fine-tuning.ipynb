{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "suffering-berlin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec850dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "prime-center",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "use_saved_embeddings = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "answering-browser",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_set = pd.read_csv('./data/Corona_NLP_train_clean_no_hash.csv')\n",
    "test_set = pd.read_csv('./data/Corona_NLP_test_clean_no_hash.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "piano-hollow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.models.roberta.modeling_tf_roberta.TFRobertaForSequenceClassification at 0x223fe765f70>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TFRobertaForSequenceClassification, RobertaConfig, RobertaTokenizer, glue_convert_examples_to_features\n",
    "\n",
    "# Initializing a BERT bert-base-uncased style configuration\n",
    "configuration = RobertaConfig()\n",
    "configuration.update({'num_labels': 3})\n",
    "# Initializing a model from the bert-base-uncased style configuration\n",
    "model = TFRobertaForSequenceClassification(configuration)\n",
    "\n",
    "# Accessing the model configuration\n",
    "configuration = model.config\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "harmful-singapore",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fce47f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_token = \"[CLS]\"\n",
    "eos_token = \"[SEP]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b0da123",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.cls_token = class_token\n",
    "tokenizer.eos_token = eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "tamil-twenty",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train = list(train_set['OriginalTweet'].apply(lambda x: class_token + x + eos_token).values)\n",
    "y_train = list(train_set['SentimentCode'].values)\n",
    "X_test = list(test_set['OriginalTweet'].apply(lambda x: class_token + x + eos_token).values)\n",
    "y_test = list(test_set['SentimentCode'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "executive-graham",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tokenizer(X_train, padding=True, truncation=True, return_tensors='tf', max_length=100)\n",
    "X_test = tokenizer(X_test, padding=True, truncation=True, return_tensors='tf', max_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0f1ba6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_onehot = np.zeros((len(y_train), 3))\n",
    "for i, hot in enumerate(y_train):\n",
    "    y_train_onehot[i ,hot] = 1\n",
    "y_test_onehot = np.zeros((len(y_test), 3))\n",
    "for i, hot in enumerate(y_test):\n",
    "    y_test_onehot[i ,hot] = 1\n",
    "y_test_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85e71b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(41106, 100), dtype=int32, numpy=\n",
       "array([[    3, 10975,  7454, ...,     1,     1,     1],\n",
       "       [    3, 10975,  7454, ...,     1,     1,     1],\n",
       "       [    3, 10975,  7454, ...,     1,     1,     1],\n",
       "       ...,\n",
       "       [    3, 10975,  7454, ...,     1,     1,     1],\n",
       "       [    3, 10975,  7454, ...,     1,     1,     1],\n",
       "       [    3, 10975,  7454, ...,     1,     1,     1]])>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8bbca10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['[CLS]advice Talk to your neighbours family to exchange phone numbers create contact list with phone numbers of neighbours schools employer chemist GP set up online shopping accounts if poss adequate supplies of regular meds but not over order[SEP]',\n",
       "       '[CLS]Coronavirus Australia: Woolworths to give elderly, disabled dedicated shopping hours amid COVID-19 outbreak [SEP]',\n",
       "       \"[CLS]My food stock is not the only one which is empty... PLEASE, don't panic, THERE WILL BE ENOUGH FOOD FOR EVERYONE if you do not take more than you need. Stay calm, stay safe. [SEP]\",\n",
       "       ...,\n",
       "       '[CLS]You know it\\x92s getting tough when is rationing toilet paper martinsville, help us out!![SEP]',\n",
       "       '[CLS]Is it wrong that the smell of hand sanitizer is starting to turn me on? [SEP]',\n",
       "       \"[CLS] Well new/used Rift S are going for $700.00 on Amazon rn although the normal market price is usually $400.00 . Prices are really crazy right now for vr headsets since HL Alex was announced and it's only been worse with COVID-19. Up to you whethe[SEP]\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set['OriginalTweet'].apply(lambda x: class_token + x + eos_token).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b8d845d",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8ad078d",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks.append(tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0.001, patience=4, verbose=1,\n",
    "    mode='auto', baseline=None, restore_best_weights=False\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc118d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath ='./models'\n",
    "callbacks.append(tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath, monitor='val_loss', verbose=1, save_best_only=False,\n",
    "    save_weights_only=False, mode='auto', save_freq='epoch',\n",
    "    options=None\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df718252",
   "metadata": {},
   "source": [
    "fit(\n",
    "    x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None,\n",
    "    validation_split=0.0, validation_data=None, shuffle=True, class_weight=None,\n",
    "    sample_weight=None, initial_epoch=0, steps_per_epoch=None,\n",
    "    validation_steps=None, validation_batch_size=None, validation_freq=1,\n",
    "    max_queue_size=10, workers=1, use_multiprocessing=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14af284a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x00000223EDC47280>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x00000223EDC47280>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1.0685WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "1000/1000 [==============================] - 1197s 1s/step - loss: 1.0684 - val_loss: 0.9891\n",
      "\n",
      "Epoch 00001: saving model to .\\models\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 1213s 1s/step - loss: 1.0051 - val_loss: 1.0383\n",
      "\n",
      "Epoch 00002: saving model to .\\models\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 1171s 1s/step - loss: 0.9661 - val_loss: 0.9423\n",
      "\n",
      "Epoch 00003: saving model to .\\models\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 1170s 1s/step - loss: 0.9356 - val_loss: 1.0357\n",
      "\n",
      "Epoch 00004: saving model to .\\models\n",
      "Epoch 5/30\n",
      " 286/1000 [=======>......................] - ETA: 12:10 - loss: 1.0586"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer=optimizer, loss=loss)\n",
    "model.fit(x=X_train['input_ids'], y=tf.constant(y_train_onehot), epochs=30, steps_per_epoch=1000, batch_size=8,\n",
    "         validation_data=(X_test['input_ids'] , tf.constant(y_test_onehot)), validation_batch_size=8, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0921514f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('roberta_classifier_early_stop.tfm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2677ad9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9720cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.logits[:32,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50eea7ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.nn.softmax(y_pred.logits, axis=1).numpy().argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d57890",
   "metadata": {},
   "outputs": [],
   "source": [
    "if"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adapted-sleeve",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if\n",
    "# stuff = model(X_tensors['input_ids'][:10], X_tensors['attention_mask'][:10], output_hidden_states=True)\n",
    "if use_saved_embeddings:\n",
    "    with open('embeddings_train.pkl', 'rb') as f:\n",
    "        train_embeddings = pickle.load(f)\n",
    "    with open('embeddings_test.pkl', 'rb') as f:\n",
    "        test_embeddings = pickle.load(f)\n",
    "else:\n",
    "    train_embeddings = get_embeddings_batchwise(X_train_tensors, 128, model)\n",
    "    test_embeddings = get_embeddings_batchwise(X_test_tensors, 128, model) \n",
    "    with open('embeddings_train.pkl', 'wb') as f:\n",
    "        pickle.dump(train_embeddings, f)\n",
    "    with open('embeddings_test.pkl', 'wb') as f:\n",
    "        pickle.dump(test_embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb0fcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_test['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changed-edgar",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import f1_score, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6b2c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_test, tf.nn.softmax(y_pred.logits, axis=1).numpy().argmax(axis=1), average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e3cf45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
