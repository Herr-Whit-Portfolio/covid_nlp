{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "suffering-berlin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-4a3f57d5652e>:2: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "occupied-wound",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaConfig, RobertaModel, pipeline, RobertaTokenizer\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "christian-warehouse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "herbal-microphone",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "answering-browser",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv('./data/Corona_NLP_train_clean.csv')\n",
    "test_set = pd.read_csv('./data/Corona_NLP_test_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "piano-hollow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing a RoBERTa configuration\n",
    "configuration = RobertaConfig()\n",
    "\n",
    "# Initializing a model from the configuration\n",
    "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# Accessing the model configuration\n",
    "configuration = model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "harmful-singapore",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "tamil-twenty",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train = list(train_set['OriginalTweet'].apply(lambda x: \"[CLS]\" + x + \"[SEP]\").values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "executive-graham",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tokenizer(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "reverse-hands",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "future-legislature",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "written-granny",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train['attention_mask'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "macro-payroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "lengths = list()\n",
    "for seq in X_train['input_ids']:\n",
    "    if len(seq) > max_len:\n",
    "        max_len = len(seq)\n",
    "    lengths.append(len(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bizarre-shoulder",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fatty-affect",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2.5210e+03, 8.6720e+03, 1.1825e+04, 1.2738e+04, 4.9370e+03,\n",
       "        3.7900e+02, 3.8000e+01, 9.0000e+00, 0.0000e+00, 3.0000e+00]),\n",
       " array([ 12. ,  25.9,  39.8,  53.7,  67.6,  81.5,  95.4, 109.3, 123.2,\n",
       "        137.1, 151. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "systematic-linux",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "continental-document",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_padded_tensor(ids, limit):\n",
    "    for i, seq in enumerate(ids['input_ids']):\n",
    "        if len(seq) > limit:\n",
    "            ids['input_ids'][i] = seq[:limit]\n",
    "            ids['attention_mask'][i] = ids['attention_mask'][i][:limit]\n",
    "        else:\n",
    "            ids['input_ids'][i] = seq + [0] * (limit - len(seq))\n",
    "            ids['attention_mask'][i] = ids['attention_mask'][i] + [0] * (limit - len(seq))\n",
    "    ids['input_ids'] = torch.LongTensor(ids['input_ids'])\n",
    "    ids['attention_mask'] = torch.LongTensor(ids['attention_mask'])\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "general-print",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensors = make_padded_tensor(X_train, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "robust-europe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([41122, 100])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tensors['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "norman-firmware",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_batchwise(X_tensors, batch_size, model, embedding_size=768):\n",
    "    number_of_batches = 1 + len(X_tensors['input_ids']) // batch_size\n",
    "    n_examples = len(X_tensors['input_ids'])\n",
    "    sequence_length = len(X_tensors['input_ids'][0])\n",
    "    embeddings = torch.zeros((n_examples, sequence_length, embedding_size))\n",
    "    for i in range(number_of_batches):\n",
    "        print(f'batch {i} of {number_of_batches}. {i * batch_size} of {n_examples} Examples')\n",
    "        results = model(X_tensors['input_ids'][i * batch_size:(i + 1) * batch_size], \n",
    "                        X_tensors['attention_mask'][i * batch_size:(i + 1) * batch_size], \n",
    "                        output_hidden_states=True) \n",
    "        hidden_dims = results[2]\n",
    "        embeddings[i * batch_size:(i + 1) * batch_size] = hidden_dims[:][0]\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "adapted-sleeve",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0 of 322. 0 of 41122 Examples\n",
      "batch 1 of 322. 128 of 41122 Examples\n",
      "batch 2 of 322. 256 of 41122 Examples\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-afd103b38958>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# stuff = model(X_tensors['input_ids'][:10], X_tensors['attention_mask'][:10], output_hidden_states=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0membeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_embeddings_batchwise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-17-35a5ad6dd95c>\u001b[0m in \u001b[0;36mget_embeddings_batchwise\u001b[1;34m(X_tensors, batch_size, model, embedding_size)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumber_of_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'batch {i} of {number_of_batches}. {i * batch_size} of {n_examples} Examples'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         results = model(X_tensors['input_ids'][i * batch_size:(i + 1) * batch_size], \n\u001b[0m\u001b[0;32m      9\u001b[0m                         \u001b[0mX_tensors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'attention_mask'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m                         output_hidden_states=True) \n",
      "\u001b[1;32m~\\miniconda3\\envs\\nlp\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nlp\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    803\u001b[0m         \u001b[0mhead_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_head_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    804\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 805\u001b[1;33m         embedding_output = self.embeddings(\n\u001b[0m\u001b[0;32m    806\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    807\u001b[0m             \u001b[0mposition_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nlp\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nlp\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[0minputs_embeds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m         \u001b[0mtoken_type_embeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoken_type_embeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nlp\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nlp\\lib\\site-packages\\torch\\nn\\modules\\sparse.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m         return F.embedding(\n\u001b[0m\u001b[0;32m    146\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nlp\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   1911\u001b[0m         \u001b[1;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1912\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1913\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1914\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# stuff = model(X_tensors['input_ids'][:10], X_tensors['attention_mask'][:10], output_hidden_states=True)\n",
    "embeddings = get_embeddings_batchwise(X_tensors, 128, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "killing-titanium",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stuff = model(X_tensors['input_ids'][:10], X_tensors['attention_mask'][:10], output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-family",
   "metadata": {},
   "outputs": [],
   "source": [
    "stuff[2][:][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formal-transcript",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "durable-eugene",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(stuff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binding-threat",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
