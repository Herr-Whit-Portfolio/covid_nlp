{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-wound",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaConfig, RobertaModel, pipeline, RobertaTokenizer\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "answering-browser",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv('./data/Corona_NLP_train_clean.csv')\n",
    "test_set = pd.read_csv('./data/Corona_NLP_test_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-hollow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing a RoBERTa configuration\n",
    "configuration = RobertaConfig()\n",
    "\n",
    "# Initializing a model from the configuration\n",
    "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# Accessing the model configuration\n",
    "configuration = model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-singapore",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-twenty",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train = list(train_set['OriginalTweet'].apply(lambda x: \"[CLS]\" + x + \"[SEP]\").values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executive-graham",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tokenizer(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reverse-hands",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "future-legislature",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "written-granny",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train['attention_mask'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "macro-payroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "lengths = list()\n",
    "for seq in X_train['input_ids']:\n",
    "    if len(seq) > max_len:\n",
    "        max_len = len(seq)\n",
    "    lengths.append(len(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bizarre-shoulder",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatty-affect",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "systematic-linux",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continental-document",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_padded_tensor(ids, limit):\n",
    "    for i, seq in enumerate(ids['input_ids']):\n",
    "        if len(seq) > limit:\n",
    "            ids['input_ids'][i] = seq[:limit]\n",
    "            ids['attention_mask'][i] = ids['attention_mask'][i][:limit]\n",
    "        else:\n",
    "            ids['input_ids'][i] = seq + [0] * (limit - len(seq))\n",
    "            ids['attention_mask'][i] = ids['attention_mask'][i] + [0] * (limit - len(seq))\n",
    "    ids['input_ids'] = torch.LongTensor(ids['input_ids'])\n",
    "    ids['attention_mask'] = torch.LongTensor(ids['attention_mask'])\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "general-print",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensors = make_padded_tensor(X_train, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "robust-europe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensors['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adapted-sleeve",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stuff = model(X_tensors['input_ids'], X_tensors['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "durable-eugene",
   "metadata": {},
   "outputs": [],
   "source": [
    "stuff[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binding-threat",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
