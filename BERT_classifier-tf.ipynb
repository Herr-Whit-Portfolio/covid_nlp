{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suffering-berlin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prime-center",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "answering-browser",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_set = pd.read_csv('./data/Corona_NLP_train_clean.csv')\n",
    "test_set = pd.read_csv('./data/Corona_NLP_test_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-hollow",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFRobertaModel, RobertaConfig, RobertaTokenizer\n",
    "\n",
    "# Initializing a BERT bert-base-uncased style configuration\n",
    "configuration = RobertaConfig()\n",
    "\n",
    "# Initializing a model from the bert-base-uncased style configuration\n",
    "model = TFRobertaModel(configuration)\n",
    "\n",
    "# Accessing the model configuration\n",
    "configuration = model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-singapore",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considerable-still",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-twenty",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train = list(train_set['OriginalTweet'].apply(lambda x: \"[CLS]\" + x + \"[SEP]\").values)\n",
    "y_train = list(train_set['SentimentCode'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executive-graham",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tokenizer(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reverse-hands",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "future-legislature",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "written-granny",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train['attention_mask'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "macro-payroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "lengths = list()\n",
    "for seq in X_train['input_ids']:\n",
    "    if len(seq) > max_len:\n",
    "        max_len = len(seq)\n",
    "    lengths.append(len(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "systematic-linux",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continental-document",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_padded_tensor(ids, limit):\n",
    "    for i, seq in enumerate(ids['input_ids']):\n",
    "        if len(seq) > limit:\n",
    "            ids['input_ids'][i] = seq[:limit]\n",
    "            ids['attention_mask'][i] = ids['attention_mask'][i][:limit]\n",
    "        else:\n",
    "            ids['input_ids'][i] = seq + [0] * (limit - len(seq))\n",
    "            ids['attention_mask'][i] = ids['attention_mask'][i] + [0] * (limit - len(seq))\n",
    "    ids['input_ids'] = tf.constant(ids['input_ids'], dtype=tf.int32)\n",
    "    ids['attention_mask'] = tf.constant(ids['attention_mask'], dtype=tf.int32)\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "general-print",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensors = make_padded_tensor(X_train, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norman-firmware",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_batchwise(X_tensors, batch_size, model, embedding_size=768):\n",
    "    number_of_batches = 1 + len(X_tensors['input_ids']) // batch_size\n",
    "    n_examples = len(X_tensors['input_ids'])\n",
    "    sequence_length = len(X_tensors['input_ids'][0])\n",
    "    embeddings = np.zeros((n_examples, embedding_size))\n",
    "    for i in range(number_of_batches):\n",
    "        print(f'batch {i} of {number_of_batches}. {i * batch_size} of {n_examples} Examples')\n",
    "        results = model(X_tensors['input_ids'][i * batch_size:(i + 1) * batch_size], \n",
    "                        X_tensors['attention_mask'][i * batch_size:(i + 1) * batch_size], \n",
    "                        output_hidden_states=True) \n",
    "        hidden_dims = results[2][1]\n",
    "        embeddings[i * batch_size:(i + 1) * batch_size] = hidden_dims[:,0]\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adapted-sleeve",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# stuff = model(X_tensors['input_ids'][:10], X_tensors['attention_mask'][:10], output_hidden_states=True)\n",
    "embeddings = get_embeddings_batchwise(X_tensors, 128, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formal-transcript",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('embeddings_train.pkl', 'wb') as f:\n",
    "    pickle.dump(embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binding-threat",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changed-edgar",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-start",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
